"""
GPT-OSSåç«¯ - é›†æˆçœŸå®AIæ¨¡å‹
"""

from fastapi import FastAPI, WebSocket, WebSocketDisconnect
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import FileResponse
import json
import asyncio
import os
import sys
from datetime import datetime
from typing import Dict

# æ·»åŠ é¡¹ç›®è·¯å¾„ä»¥å¯¼å…¥ç°æœ‰çš„AIæ¨¡å—
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

app = FastAPI(title="GPT-OSS Real AI", version="3.0.0")

# CORSè®¾ç½®
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# å…¨å±€å˜é‡
websocket_connections: Dict[str, WebSocket] = {}
ai_instances: Dict[str, object] = {}
global_ai_instance = None  # å…¨åŸŸå…±äº«çš„AIå¯¦ä¾‹
frontend_path = os.path.join(os.path.dirname(os.path.dirname(__file__)), "frontend")

@app.on_event("startup")
async def startup_event():
    """åº”ç”¨å¯åŠ¨æ—¶çš„åˆå§‹åŒ–"""
    global global_ai_instance
    
    print("ğŸš€ GPT-OSS Real AI å¯åŠ¨ä¸­...")
    print("ğŸ”„ æ­£åœ¨åˆå§‹åŒ–AIæ¨¡å‹...")
    
    # æ£€æŸ¥æ˜¯å¦å¯ä»¥åŠ è½½çœŸå®æ¨¡å‹
    try:
        from conversational_ai import ConversationalAI
        from advanced_chat import AdvancedConversationalAI
        print("âœ… AIæ¨¡å—åŠ è½½æˆåŠŸ")
        
        # åˆ›å»ºå…¨åŸŸå…±äº«çš„AIå¯¦ä¾‹ï¼ˆåªè¼‰å…¥ä¸€æ¬¡ï¼‰
        global_ai_instance = AdvancedConversationalAI(
            model_name="GPT_OSS",  # ä½¿ç”¨ GPT-OSS æ¨¡å‹
            generation_style="conservative"
        )
        print("âœ… AIæ¨¡å‹åˆå§‹åŒ–æˆåŠŸ")
        
    except Exception as e:
        print(f"âš ï¸ AIæ¨¡å‹åŠ è½½å¤±è´¥: {e}")
        print("ğŸ’¡ å°†ä½¿ç”¨æ™ºèƒ½æ¨¡æ‹Ÿæ¨¡å¼")
        global_ai_instance = None

@app.get("/")
async def serve_frontend():
    """æœåŠ¡å‰ç«¯é¡µé¢"""
    index_path = os.path.join(frontend_path, "index_new.html")
    if os.path.exists(index_path):
        return FileResponse(index_path, media_type="text/html")
    return {"error": "Frontend not found", "path": index_path}

@app.get("/models")
async def get_models():
    """è·å–å¯ç”¨æ¨¡å‹"""
    try:
        config_path = os.path.join(os.path.dirname(os.path.dirname(__file__)), "models_config.json")
        with open(config_path, 'r', encoding='utf-8') as f:
            config = json.load(f)
        
        models = []
        for name, info in config["models"].items():
            models.append({
                "name": name,
                "model_id": info["model_id"],
                "description": info.get("description", "")
            })
        return models
    except:
        return [
            {
                "name": "GPT_OSS",
                "model_id": "openai/gpt-oss-20b", 
                "description": "å¤§å‹å¯¹è¯æ¨¡å‹ï¼Œè´¨é‡é«˜"
            },
            {
                "name": "medium",
                "model_id": "microsoft/DialoGPT-medium",
                "description": "ä¸­å‹å¯¹è¯æ¨¡å‹ï¼Œå¹³è¡¡é€Ÿåº¦å’Œè´¨é‡"
            }
        ]

@app.get("/status")
async def get_status():
    """ç³»ç»ŸçŠ¶æ€"""
    return {
        "status": "running",
        "version": "3.0.0-real-ai",
        "connections": len(websocket_connections),
        "ai_instances": len(ai_instances),
        "timestamp": datetime.now().isoformat()
    }

@app.websocket("/ws/{session_id}")
async def websocket_endpoint(websocket: WebSocket, session_id: str):
    """WebSocketè¿æ¥å¤„ç†"""
    await websocket.accept()
    websocket_connections[session_id] = websocket
    
    print(f"âœ“ WebSocketè¿æ¥å»ºç«‹: {session_id}")
    
    try:
        while True:
            # æ¥æ”¶æ¶ˆæ¯
            data = await websocket.receive_text()
            message_data = json.loads(data)
            print(f"æ”¶åˆ°æ¶ˆæ¯: {message_data}")
            
            if message_data.get("type") == "chat":
                await handle_chat_message(websocket, session_id, message_data)
            elif message_data.get("type") == "interrupt":
                await handle_interrupt(websocket)
            else:
                print(f"æœªçŸ¥æ¶ˆæ¯ç±»å‹: {message_data.get('type')}")
    
    except WebSocketDisconnect:
        print(f"âœ— WebSocketè¿æ¥æ–­å¼€: {session_id}")
        cleanup_session(session_id)
    except Exception as e:
        print(f"WebSocketé”™è¯¯: {e}")
        cleanup_session(session_id)

def cleanup_session(session_id: str):
    """æ¸…ç†ä¼šè¯"""
    if session_id in websocket_connections:
        del websocket_connections[session_id]
    if session_id in ai_instances:
        del ai_instances[session_id]

async def handle_chat_message(websocket: WebSocket, session_id: str, message_data: dict):
    """å¤„ç†èŠå¤©æ¶ˆæ¯"""
    user_message = message_data.get("message", "")
    model_name = message_data.get("model_name", "GPT_OSS")
    generation_style = message_data.get("generation_style", "conservative")
    
    # 1. ç¡®è®¤æ”¶åˆ°ç”¨æˆ·æ¶ˆæ¯
    await websocket.send_text(json.dumps({
        "type": "user_message",
        "message": user_message,
        "timestamp": datetime.now().isoformat()
    }))
    
    # 2. å¼€å§‹ç”Ÿæˆå“åº”
    await websocket.send_text(json.dumps({
        "type": "generation_start",
        "timestamp": datetime.now().isoformat()
    }))
    
    try:
        # 3. è·å–æˆ–åˆ›å»ºAIå®ä¾‹
        ai_instance = get_or_create_ai_instance(session_id, model_name, generation_style)
        
        # 4. ç”ŸæˆçœŸå®AIå“åº”
        if ai_instance:
            print(f"ä½¿ç”¨çœŸå®AIæ¨¡å‹ç”Ÿæˆå›ç­”: {model_name}")
            response = await generate_real_ai_response(ai_instance, user_message)
        else:
            print("ä½¿ç”¨æ™ºèƒ½æ¨¡æ‹Ÿæ¨¡å¼")
            response = generate_smart_fallback_response(user_message)
        
        # 5. å‘é€AIå“åº”
        await websocket.send_text(json.dumps({
            "type": "ai_response",
            "message": response,
            "timestamp": datetime.now().isoformat()
        }))
        
    except Exception as e:
        print(f"ç”Ÿæˆå“åº”å¤±è´¥: {e}")
        await websocket.send_text(json.dumps({
            "type": "ai_response",
            "message": f"æŠ±æ­‰ï¼Œç”Ÿæˆå›ç­”æ—¶é‡åˆ°é”™è¯¯: {str(e)}",
            "timestamp": datetime.now().isoformat()
        }))
    
    # 6. ç»“æŸç”Ÿæˆ
    await websocket.send_text(json.dumps({
        "type": "generation_end",
        "timestamp": datetime.now().isoformat()
    }))

def get_or_create_ai_instance(session_id: str, model_name: str, generation_style: str):
    """è·å–æˆ–åˆ›å»ºAIå®ä¾‹ - ä½¿ç”¨å…¨åŸŸå…±äº«å¯¦ä¾‹"""
    global global_ai_instance
    
    # å¦‚æœå·²ç¶“æœ‰ç‚ºæ­¤æœƒè©±å‰µå»ºçš„å¯¦ä¾‹ï¼Œè¿”å›å®ƒ
    if session_id in ai_instances:
        return ai_instances[session_id]
    
    # ä½¿ç”¨å…¨åŸŸå…±äº«çš„AIå¯¦ä¾‹ï¼ˆé¿å…é‡è¤‡è¼‰å…¥æ¨¡å‹ï¼‰
    if global_ai_instance is not None:
        ai_instances[session_id] = global_ai_instance
        print(f"âœ… ä¸ºä¼šè¯ {session_id} ä½¿ç”¨å…±äº«AIå®ä¾‹")
        return global_ai_instance
    else:
        print(f"âš ï¸ å…¨åŸŸAIå¯¦ä¾‹ä¸å¯ç”¨ï¼Œæœƒè©± {session_id} ç„¡æ³•ä½¿ç”¨çœŸå¯¦AI")
        return None

async def generate_real_ai_response(ai_instance, user_message: str) -> str:
    """ä½¿ç”¨çœŸå®AIæ¨¡å‹ç”Ÿæˆå“åº”"""
    try:
        print(f"æº–å‚™ç”ŸæˆAIå›æ‡‰ï¼Œè¼¸å…¥: {user_message[:50]}...")
        
        # åœ¨åå°çº¿ç¨‹ä¸­è¿è¡ŒAIç”Ÿæˆï¼Œé¿å…é˜»å¡WebSocketï¼Œå¢åŠ è¶…æ™‚æ©Ÿåˆ¶
        response = await asyncio.wait_for(
            asyncio.get_event_loop().run_in_executor(
                None, ai_instance.generate_response, user_message
            ),
            timeout=60.0  # 60ç§’è¶…æ™‚
        )
        
        print(f"AIå›æ‡‰ç”ŸæˆæˆåŠŸ: {response[:100] if response else 'None'}...")
        return response
        
    except asyncio.TimeoutError:
        error_msg = "AIæ¨¡å‹å›æ‡‰è¶…æ™‚ï¼ˆ60ç§’ï¼‰ï¼Œè«‹ç¨å¾Œå†è©¦"
        print(f"è¶…æ™‚éŒ¯èª¤: {error_msg}")
        return error_msg
    except Exception as e:
        error_msg = f"AIæ¨¡å‹å›ç­”æ—¶å‡ºç°é”™è¯¯: {str(e)}"
        print(f"ç”ŸæˆéŒ¯èª¤: {error_msg}")
        import traceback
        traceback.print_exc()
        return error_msg

def generate_smart_fallback_response(user_message: str) -> str:
    """æ™ºèƒ½åå¤‡å›ç­”ï¼ˆå½“çœŸå®AIä¸å¯ç”¨æ—¶ï¼‰"""
    message = user_message.lower()
    
    # æ›´æ™ºèƒ½çš„æ¨¡æ‹Ÿå›ç­”
    if any(word in message for word in ["ä½ å¥½", "hello", "hi", "å—¨"]):
        return f"ä½ å¥½ï¼æˆ‘æ˜¯GPT-OSSæ™ºèƒ½åŠ©æ‰‹ã€‚å¾ˆé«˜å…´ä¸ä½ äº¤æµï¼\n\nå…³äºä½ è¯´çš„ã€Œ{user_message}ã€ï¼Œæˆ‘æƒ³è¯´è™½ç„¶ç›®å‰æˆ‘åœ¨æ¨¡æ‹Ÿæ¨¡å¼ä¸‹è¿è¡Œï¼Œä½†æˆ‘ä»ç„¶è‡´åŠ›äºä¸ºä½ æä¾›æœ‰ä»·å€¼çš„å¯¹è¯ä½“éªŒã€‚"
    
    elif any(word in message for word in ["æ¨¡å‹", "AI", "æ™ºèƒ½"]):
        return f"å…³äºAIæ¨¡å‹çš„é—®é¢˜å¾ˆæœ‰è¶£ï¼\n\nä½ è¯¢é—®ï¼šã€Œ{user_message}ã€\n\nç›®å‰ç³»ç»Ÿæ”¯æŒå¤šç§æ¨¡å‹ï¼ŒåŒ…æ‹¬openai/gpt-oss-20bã€‚æˆ‘æ­£åœ¨åŠªåŠ›ä¸ºä½ æä¾›æœ€ä½³çš„å¯¹è¯ä½“éªŒã€‚ä½ è¿˜æƒ³äº†è§£ä»€ä¹ˆå…·ä½“æ–¹é¢å‘¢ï¼Ÿ"
    
    elif any(word in message for word in ["ä¸ºä»€ä¹ˆ", "å¦‚ä½•", "æ€ä¹ˆ"]):
        return f"è¿™æ˜¯ä¸€ä¸ªå¾ˆå¥½çš„é—®é¢˜ï¼\n\né’ˆå¯¹ã€Œ{user_message}ã€ï¼Œè®©æˆ‘ä»å‡ ä¸ªè§’åº¦æ¥åˆ†æï¼š\n\n1. é¦–å…ˆéœ€è¦ç†è§£é—®é¢˜çš„æ ¸å¿ƒ\n2. ç„¶åè€ƒè™‘å¯èƒ½çš„è§£å†³æ–¹æ¡ˆ\n3. æœ€åæä¾›å®ç”¨çš„å»ºè®®\n\nä½ æ˜¯æƒ³äº†è§£æ›´å…·ä½“çš„å“ªä¸ªæ–¹é¢å‘¢ï¼Ÿ"
    
    elif "å¼€å‘" in message or "ç¼–ç¨‹" in message or "ä»£ç " in message:
        return f"å…³äºå¼€å‘å’Œç¼–ç¨‹çš„è¯é¢˜æˆ‘å¾ˆæ„Ÿå…´è¶£ï¼\n\nä½ æåˆ°ï¼šã€Œ{user_message}ã€\n\nåœ¨è½¯ä»¶å¼€å‘é¢†åŸŸï¼Œæœ‰å¾ˆå¤šå€¼å¾—æ¢è®¨çš„å†…å®¹ã€‚æ— è®ºæ˜¯æ¶æ„è®¾è®¡ã€ä»£ç ä¼˜åŒ–ï¼Œè¿˜æ˜¯æ–°æŠ€æœ¯å­¦ä¹ ï¼Œæˆ‘éƒ½å¯ä»¥å’Œä½ äº¤æµã€‚\n\nä½ ç›®å‰åœ¨å¼€å‘ä»€ä¹ˆé¡¹ç›®ï¼Œæˆ–è€…é‡åˆ°äº†ä»€ä¹ˆæŠ€æœ¯æŒ‘æˆ˜å—ï¼Ÿ"
    
    else:
        return f"æ„Ÿè°¢ä½ çš„æ¶ˆæ¯ï¼šã€Œ{user_message}ã€\n\nè¿™æ˜¯ä¸€ä¸ªå¾ˆæœ‰æ„æ€çš„è¯é¢˜ã€‚è™½ç„¶æˆ‘ç›®å‰å¤„äºæ¨¡æ‹Ÿæ¨¡å¼ï¼Œä½†æˆ‘ä¼šå°½åŠ›ä¸ºä½ æä¾›æœ‰ä»·å€¼çš„å›åº”ã€‚\n\nå¦‚æœä½ æƒ³ä½“éªŒå®Œæ•´çš„AIå¯¹è¯åŠŸèƒ½ï¼Œç³»ç»Ÿæ­£åœ¨åŠªåŠ›åŠ è½½çœŸå®çš„openai/gpt-oss-20bæ¨¡å‹ã€‚\n\næœ‰ä»€ä¹ˆå…¶ä»–é—®é¢˜æˆ‘å¯ä»¥å¸®ä½ æ€è€ƒçš„å—ï¼Ÿ"

async def handle_interrupt(websocket: WebSocket):
    """å¤„ç†ä¸­æ–­è¯·æ±‚"""
    await websocket.send_text(json.dumps({
        "type": "generation_interrupted",
        "message": "å¯¹è¯å·²è¢«ä¸­æ–­",
        "timestamp": datetime.now().isoformat()
    }))

if __name__ == "__main__":
    import uvicorn
    print("ğŸš€ å¯åŠ¨GPT-OSS Real AIæœåŠ¡å™¨...")
    print("ğŸ“¡ åœ°å€: http://127.0.0.1:8000")
    print("ğŸ¤– é›†æˆçœŸå®AIæ¨¡å‹æ”¯æŒ")
    uvicorn.run(app, host="127.0.0.1", port=8000, log_level="info")